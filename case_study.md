# Оптимизация алгоритма просчета графа

## Описание проблемы

### Описание решаемой проблемы

Основная задача проекта - сбор определенного вида аналитики исходя из данных, представленных в виде 
графа. Аналитика собирается из графа в несколько этапов:  
1 Сбор основного большого графа  
2 Проход по этому графу в несколько этапов  
3 Анализ графа  
4 Формирование xls, xml отчетов и структуры для выгрузки данных через API  

## Описание возникшей проблемы с производительностью

Возникла необходимость добавления нового функционала: сбора большей информации с узлов графа. Это 
привело к увеличению длительности всего просчета с двух до 28 часов. При этом 26 часов занимает этап
анализа графа. Исходя из этого было решено оптимизировать именно этот этап просчета.

##  Формирование метрики

За метрику было выбрано время проведения анализа графа. В качестве бюджета было задано значение в 90 
минут при условии внедрения нового функционала.

## Гарантия работы оптимизируемой программы

В проекте уже существует набор написанных тестов, который, однако, не полностью покрывает функционал
программы. При оптимизации каждого отдельного участка программы, необходимо предварительно покрыть 
его тестами. Для тестирования будет использоваться `rspec`.

## Feedback-loop

Так как анализ графа выполняется в одном большом методе, ты было решено найти основные точки роста, 
выделить их в сервисные объекты и проводить оптимизацию для каждой отдельной точки роста в своем 
feedback-loop'e. В итоге feedback-loop будет выглядеть следующим образом:  
1 Найти основную точку роста  
2 Изолировать данную точку роста  
3 Собрать необходимый для оптимизации набор данных  
4 Профилирование с помощью ruby_prof - calgrind -- Оптимизация -- Проверка работы процессов с 
помощью тестов -- Написания тестов на производительность для закрепления результата оптимизации

## Поиск точек роста

### Анализ основных точек роста

Так как анализ дерева графа при текущем функционале выполняется не более двух часов, то для
определения основных точек роста было решено использовать `ruby-progressbar` и `ruby_prof` в режиме
`callgrind`. После расстановки progressbar'ов и настройки трассирующего профилировщика были выяснены 
следующие факты:  
1 Большую часть времени занимает процесс мерджа структур, получающихся из графа при его анализе  
2 Следующими примерно равными точками роста является формирование деревьев из нескольких частей 
графа  
3 Очень долгое время занимает построение CSV отчета на основе проанализированных данных   
4 С помощью профилировщика было выяснено, что большую часть процессорного времени занимает метод 
`IO::select`, который вызывается библиотекой, работающей с redis'ом в основном методом
`Redis/Connection/SocketMixin::_read_from_socket`. Причем, проблема не в том, что существуют 
какие-то отдельные долгие методы в библиотеке, а в количестве обращений к Redis'у. Redis - основной
инструмент, используемый для анализа текущего графа, поэтому уже на этом этапе было решено при 
оптимизации точек роста использовать механизм `redis pipelining` для сокращения общего количества 
запросов к Redis'у.

### Оптмизация мерджа структур

Для упрощения оптимизации мерджа структур и в целях рефакторинга просчета было решено вынести 
процесс мерджа в сервисный объект. Так как для процесса мерджа не было написано тестов, то сначала 
было решено покрыть тестами данный функционал. После покрытия данного сервисного объекта тестами 
было решено провести профилирование данного участка программы изолированно от оставшейся части 
просчета. В качестве профилировщика был выбран `ruby_prof`. В качестве входных данных были выбраны 
структуры, которые формируются при текущем просчете без внедрения нового функционала.  
В результате было выяснено, что с большим отрывом основной точкой роста является операция 
`IO::select`, вызываемая `Redis/Connection/SocketMixin::_read_from_socket`. В процессе мерджа 
работа с Redis'ом производится только в случае необходимости рекурсивного поиска по графу ноды по 
определенному признаку. Было решено до минимума сократить количество таких поисков и, в случае 
необходимости, оптимизировать его работу. Благодаря написанным тестам и дальнейшему анализу мерджа 
деревьев было выяснено, что этот поиск на этапе мерджа не имеет смысла, так как данные к моменту 
мерджа структур уже есть и повторно их искать не надо. Таким образом, время мерджа сократилось 
более чем в 400 раз и потенциально сократилось время формирования общей структуры, из которой 
впоследствии формируются отчеты. Далее были поправлены тесты, и был закреплен результат оптимизации 
с помощью `rspec-benchmark`. Для закрепления результатов оптимизации был создан файл `sample.json`,
в котором находятся данные для тестирования производительности оптимизированной части системы. По 
результатам оптимизации на подготовленных данных `rspec-benchmark` выдает 21 мс. Далее был 
произведен рефакторинг данного процесса без значительного изменения его производительности.

### Оптимизация процесса формирования отчета

Следующая точка роста - формирования отчета. Было решено вынести процесс формирования отчета в 
отдельный сервисный объект. Так как в проекте нет тестов на данный функционал, то для гарантии 
работы оптимизированной программы было необходимо покрыть тестами процесс формирования отчета. 
После покрытия тестами нужного функционала, был создан сэмпл, состоящий из 500 компаний, из 
которых формируется этот отчет. Сервис напрямую использует Redis, поэтому необходимые структуры 
данных были созданы в редисе, а в самом сервисе был создан метод, использующий новые структуры 
данных, но без изменения самого функционала сервиса. Тестовый набор данных обрабатывается старым 
алгоритмом ~ за 3.5 секунды. Так как в итоге получается большой файл, то было решено записывать 
данные в отчет в потоковом стиле. Благодаря этому время работы сборщика отчета на выбранном сэмпле 
данных сократилось до 2.3 секунд. Также был проведен замер потребления памяти. Для этого сэмпл 
данных был расширен до 5000 компаний. В результате потоковой записи в CSV файл удалось сократить 
потребление памяти для всего объема компаний до 90 МБ (против 500 МБ).  
Далее для сбора данных  был использован `Redis Pipelining`, чтобы сократить количество запросов в 
`Redis` и таким образом сократить `RTT`.  
Данные оптимизации позволили сократить время формирования отчета на 40%. Использование напрямую
значений `Redis` вместо формирования промежуточных Ruby объектов сократило время формирования отчета 
еще на 5%. Результаты оптимизации были закреплены с помощью `rspec-benchmark`.  
Сам файл формировался из одинакового пула компаний. При этом формировался он несколько раз во время 
просчета и всегда оставался одинаковым, из-за чего совершалось много лишней работы. Чтобы избежать 
повторного формирования отчета результаты первичного отчета используются на протяжении всего 
просчета. В результате время формирования отчета сократилось еще в два раза.

### Оптимизация рекурсивного поиска узлов графа по заданному признаку

Для удобства тестирования и оптимизации рекурсивного поиска узлов графа по заданному признаку 
соответствующий функционал был вынесен из основного файла анализа графа в отдельный сервис. Как и 
на предыдущих этапах тестов написано не было, поэтому сначала данный сервис был покрыт тестами. 
После этого был собран тестовый датасет для тестирования гипотез оптимизации. В качестве тестового 
датасета была выбрана достаточно большая часть графа. В процессе оптимизации было выяснено, что 
алгоритм часто возвращает одно и то же значение для разных узлов. Эти результаты были 
проанализированы и применены для оптимизации данного алгоритма. В частности, теперь алгоритм помнит 
посещенные узлы и старается сначала проверить узлы в памяти, а уже потом продолжать рекурсивный 
поиск узлов.  
Данная оптимизация сократила время просчета для выбранного датасета с 13 минут до 3-х минут.

### Перевод обогащения данными компаний перед формированием отчетов в многопоточный режим

Рекурсивный поиск узлов графа по заданному признаку для части компаний производился в одном потоке. 
Данный механизм был вынесен в отдельный сервис, покрыт тестами и был переписан для работы в 
многопоточном режиме, что привело к ускорению обогащения данными в четыре раза.

### Дальнейшая оптимизация обогащения данными

Ряд данных добавлялся в структуру, из которой впоследствии формируются отчеты, в несколько проходов 
по всему графу. Данный механизм был перенесен на предыдущий этап просчета, что еще ускорило данный 
этап просчета и сделало код чище.

### Дополнительная защита от деградации эффективности алгоритма

Время работы каждого оптимизированного этапа просчета теперь логируется. Время работы можно 
посмотреть и сравнить в `Kibana`.

## Результаты оптимизации

В результате проведенной оптимизации время работы этапа анализа графа сократилось с 26 часов до 65 
минут, а общее время просчета сократилось с 28 часов до 4.5 часов. При этом анализ графа и 
формирование различных отчетов занимает менее часа, что укладывается в поставленный бюджет 
оптимизации.  
Несмотря на то, что можно провести дальнейшую оптимизацию, на данный момент было решено остановиться
на достигнутых результатах.